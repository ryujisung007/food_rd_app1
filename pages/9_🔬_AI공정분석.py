"""ğŸ”¬ AI ê³µì • ë¶„ì„"""
import streamlit as st
import pandas as pd
import sys, os
PAGE_DIR = os.path.dirname(os.path.abspath(__file__))
APP_DIR = os.path.dirname(PAGE_DIR)
if APP_DIR not in sys.path:
    sys.path.insert(0, APP_DIR)
from data.common import *

st.set_page_config(page_title="AIê³µì •ë¶„ì„", page_icon="ğŸ”¬", layout="wide")
st.markdown("# ğŸ”¬ AI ê³µì • ë¶„ì„ & PDF í•™ìŠµ")
st.markdown("ê³µì • ê´€ë ¨ PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ AI ì—°êµ¬ì›ì´ ë¶„ì„í•˜ì—¬ ê³µì • ë¦¬ìŠ¤í¬ë¥¼ ê²€í† í•©ë‹ˆë‹¤")
st.markdown("---")

if "pdf_texts" not in st.session_state:
    st.session_state.pdf_texts = {}
if "ai_analysis" not in st.session_state:
    st.session_state.ai_analysis = {}

# â”â”â” ì‚¬ì´ë“œë°”: PDF ì—…ë¡œë“œ â”â”â”
with st.sidebar:
    st.markdown("### ğŸ“„ PDF ì—…ë¡œë“œ")
    st.caption("HACCP ê´€ë¦¬ê¸°ì¤€ì„œ, ê³µì •ë„, ìœ„í•´ë¶„ì„ì„œ ë“±")

    uploaded_files = st.file_uploader(
        "PDF íŒŒì¼ ì„ íƒ (ë³µìˆ˜ ê°€ëŠ¥)", type=["pdf"],
        accept_multiple_files=True, key="process_pdfs"
    )

    if uploaded_files:
        for uf in uploaded_files:
            if uf.name not in st.session_state.pdf_texts:
                with st.spinner(f"ğŸ“„ {uf.name} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
                    text = extract_pdf_text(uf)
                    if text:
                        st.session_state.pdf_texts[uf.name] = text
                        st.success(f"âœ… {uf.name} ({len(text)}ì)")
                    else:
                        st.error(f"âŒ {uf.name} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")

    if st.session_state.pdf_texts:
        st.markdown("---")
        st.markdown("**í•™ìŠµëœ ë¬¸ì„œ:**")
        for name, text in st.session_state.pdf_texts.items():
            st.markdown(f"- ğŸ“„ {name} ({len(text):,}ì)")

# â”â”â” ë©”ì¸ â”â”â”
tab1, tab2, tab3 = st.tabs(["ğŸ”¬ AI ê³µì • ê²€í† ", "ğŸ“„ PDF ë‚´ìš© í™•ì¸", "ğŸ“Š ë¶„ì„ ë¹„êµí‘œ"])

with tab1:
    st.markdown("### ğŸ”¬ AI ì—°êµ¬ì› ê³µì • ê²€í† ")

    form = st.session_state.get("ai_formulation")

    # ë¶„ì„ ëŒ€ìƒ ì„ íƒ
    analysis_target = st.selectbox("ë¶„ì„ ëŒ€ìƒ", [
        "ì „ì²´ ê³µì • ë¦¬ìŠ¤í¬ ë¶„ì„",
        "HACCP CCP ê²€í† ",
        "ì‚´ê·  ê³µì • ì ì •ì„±",
        "ì›ë£Œ ì•ˆì „ì„± ê²€í† ",
        "ì œì¡°í™˜ê²½ ìœ„ìƒê´€ë¦¬",
        "ì‚¬ìš©ì ì •ì˜ ì§ˆë¬¸",
    ])

    if analysis_target == "ì‚¬ìš©ì ì •ì˜ ì§ˆë¬¸":
        custom_q = st.text_area("ë¶„ì„ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: íƒ„ì‚°ìŒë£Œì˜ ì‚´ê·  ì˜¨ë„ì™€ ì‹œê°„ ê¸°ì¤€ì€?")
    else:
        custom_q = ""

    # PDF ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    pdf_context = ""
    if st.session_state.pdf_texts:
        selected_pdfs = st.multiselect("ì°¸ì¡°í•  PDF ì„ íƒ", list(st.session_state.pdf_texts.keys()),
                                        default=list(st.session_state.pdf_texts.keys()))
        for name in selected_pdfs:
            # í† í° ì œí•œì„ ìœ„í•´ ì•ë¶€ë¶„ë§Œ
            pdf_context += f"\n\n[ë¬¸ì„œ: {name}]\n{st.session_state.pdf_texts[name][:3000]}"

    if st.button("ğŸ¤– AI ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True):
        with st.spinner("AI ì—°êµ¬ì›ì´ ë¶„ì„ ì¤‘..."):
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            formulation_info = ""
            if form:
                formulation_info = f"""
í˜„ì¬ ì œí’ˆ: {form.get('productName', 'ë¯¸ì •')}
Brix: {form.get('brix', '-')}, pH: {form.get('pH', '-')}
ì›ë£Œ: {', '.join(i['name'] for i in form.get('ingredients', []))}
"""
            question = custom_q if custom_q else analysis_target

            prompt = f"""ë‹¹ì‹ ì€ ì‹í’ˆê³µí•™ R&D ì—°êµ¬ì›ì´ì HACCP ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

{formulation_info}

ê³µì • ë‹¨ê³„:
{chr(10).join(f"- {s['name']}: ìœ„í•´ìš”ì†Œ={s['risk']}, ê´€ë¦¬ê¸°ì¤€={s['control']}" for s in PROCESS_STEPS)}

{f'ì°¸ì¡° ë¬¸ì„œ ë‚´ìš©:{pdf_context}' if pdf_context else '(ì°¸ì¡° ë¬¸ì„œ ì—†ìŒ)'}

ë¶„ì„ ìš”ì²­: {question}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. í˜„í™© ë¶„ì„
2. í•µì‹¬ ë¦¬ìŠ¤í¬ ìš”ì¸ (êµ¬ì²´ì )
3. ê´€ë¦¬ ê¸°ì¤€ ì ì •ì„± í‰ê°€
4. ê°œì„  ê¶Œê³ ì‚¬í•­
5. PDF ë¬¸ì„œ ê¸°ë°˜ ê·¼ê±° (ìˆëŠ” ê²½ìš°)

ì „ë¬¸ì ì´ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë˜, í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."""

            try:
                import json as json_mod
                resp = __import__("requests").post(
                    "https://api.anthropic.com/v1/messages",
                    headers={"Content-Type": "application/json"},
                    json={
                        "model": "claude-sonnet-4-20250514",
                        "max_tokens": 2000,
                        "messages": [{"role": "user", "content": prompt}]
                    },
                    timeout=60,
                )
                data = resp.json()
                analysis = data.get("content", [{}])[0].get("text", "ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„
                analysis = f"""## {analysis_target} ë¶„ì„ ê²°ê³¼

### 1. í˜„í™© ë¶„ì„
{f'ì œí’ˆ "{form["productName"]}" ê¸°ì¤€ ' if form else 'ì¼ë°˜ ìŒë£Œ '}ì œì¡°ê³µì • 8ë‹¨ê³„ë¥¼ ê²€í† í•˜ì˜€ìŠµë‹ˆë‹¤.

### 2. í•µì‹¬ ë¦¬ìŠ¤í¬ ìš”ì¸
- **ì‚´ê·  ê³µì • (CCP-1)**: ì˜¨ë„Â·ì‹œê°„ ê´€ë¦¬ê°€ ìµœìš°ì„ . HTST 72Â°C/15ì´ˆ ë˜ëŠ” UHT 135Â°C/2ì´ˆ ê¸°ì¤€ ì¤€ìˆ˜ í•„ìˆ˜
- **ì¶©ì „Â·ë°€ë´‰ (CCP-2)**: ìš©ê¸° ë°€ë´‰ ë¶ˆëŸ‰ ì‹œ ë¯¸ìƒë¬¼ ì¬ì˜¤ì—¼ ìœ„í—˜
- **ê³„ëŸ‰Â·ë°°í•©**: ë°°í•© ì˜¤ì°¨ ì‹œ í’ˆì§ˆ í¸ì°¨ ë°œìƒ, ì „ìì €ìš¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìˆ˜

### 3. ê´€ë¦¬ ê¸°ì¤€ ì ì •ì„±
- ì‚´ê·  ì¡°ê±´: {'ì ì • (pH ' + str(form.get("pH", 3.5)) + ' ê¸°ì¤€)' if form else 'í™•ì¸ í•„ìš”'}
- ëª¨ë‹ˆí„°ë§: CCPë³„ ì—°ì† ì˜¨ë„ ê¸°ë¡ì¥ì¹˜(RTD) ì„¤ì¹˜ ê¶Œì¥
- ê²€ì¦: ì›” 1íšŒ ì´ìƒ ë¯¸ìƒë¬¼ í•œë„ ì‹œí—˜ ì‹¤ì‹œ

### 4. ê°œì„  ê¶Œê³ ì‚¬í•­
1. ì‚´ê·  ê³µì •ì˜ Fâ‚€ê°’ ê³„ì‚° ë° ê²€ì¦ ì‹¤ì‹œ
2. ìë™ ë°°í•© ì‹œìŠ¤í…œ ë„ì…ìœ¼ë¡œ ê³„ëŸ‰ ì˜¤ì°¨ ìµœì†Œí™”
3. ë°€ë´‰ í›„ ê¸°ë°€ì‹œí—˜ 100% ì „ìˆ˜ê²€ì‚¬ ì‹¤ì‹œ
4. HACCP íŒ€ ì •ê¸°êµìœ¡ (ë¶„ê¸° 1íšŒ ì´ìƒ)

### 5. ë¬¸ì„œ ê¸°ë°˜ ê·¼ê±°
{'ì—…ë¡œë“œëœ PDF (' + ', '.join(st.session_state.pdf_texts.keys()) + ')ë¥¼ ì°¸ì¡°í•˜ì˜€ìŠµë‹ˆë‹¤.' if st.session_state.pdf_texts else 'ì°¸ì¡° ë¬¸ì„œê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.'}

âš ï¸ *ë³¸ ë¶„ì„ì€ AI ê¸°ë°˜ ì°¸ê³  ìë£Œì´ë©°, ìµœì¢… íŒë‹¨ì€ ì‹í’ˆì•ˆì „ ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.*
"""

            st.session_state.ai_analysis[analysis_target] = analysis
            st.markdown(analysis)

    # ì´ì „ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if st.session_state.ai_analysis and not st.session_state.get("_just_analyzed"):
        with st.expander("ğŸ“‚ ì´ì „ ë¶„ì„ ê²°ê³¼", expanded=False):
            for title, text in st.session_state.ai_analysis.items():
                st.markdown(f"#### {title}")
                st.markdown(text[:500] + "..." if len(text) > 500 else text)
                st.markdown("---")


with tab2:
    st.markdown("### ğŸ“„ ì—…ë¡œë“œëœ PDF ë‚´ìš©")
    if not st.session_state.pdf_texts:
        st.info("ğŸ“¤ ì‚¬ì´ë“œë°”ì—ì„œ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (HACCP ë¬¸ì„œ, ê³µì •ë„, ìœ„í•´ë¶„ì„ì„œ ë“±)")
    else:
        for name, text in st.session_state.pdf_texts.items():
            with st.expander(f"ğŸ“„ {name} ({len(text):,}ì)", expanded=False):
                # í‚¤ì›Œë“œ ê²€ìƒ‰
                kw = st.text_input(f"ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ ({name})", key=f"kw_{name}")
                if kw:
                    lines = text.split("\n")
                    matched = [l for l in lines if kw.lower() in l.lower()]
                    st.markdown(f"**'{kw}' í¬í•¨ í–‰: {len(matched)}ê±´**")
                    for m in matched[:30]:
                        st.markdown(f"- ...{m.strip()}...")
                else:
                    st.text_area("ì „ë¬¸", text[:5000], height=400, key=f"full_{name}")
                    if len(text) > 5000:
                        st.caption(f"(ì „ì²´ {len(text):,}ì ì¤‘ ìƒìœ„ 5,000ì í‘œì‹œ)")


with tab3:
    st.markdown("### ğŸ“Š ê³µì • ë¶„ì„ ë¹„êµí‘œ")
    st.markdown("ê° ê³µì • ë‹¨ê³„ë³„ ìœ„í•´ìš”ì†ŒÂ·ê´€ë¦¬ê¸°ì¤€ì„ PDF ë¬¸ì„œì™€ ëŒ€ì¡°")

    compare_data = []
    for s in PROCESS_STEPS:
        row = {
            "ê³µì •": f"{s['icon']} {s['name']}",
            "ìœ„í•´ìš”ì†Œ": s["risk"],
            "ê´€ë¦¬ê¸°ì¤€": s["control"],
            "ë¦¬ìŠ¤í¬": {"high":"ğŸ”´ë†’ìŒ","mid":"ğŸŸ¡ë³´í†µ","low":"ğŸŸ¢ë‚®ìŒ"}[s["level"]],
            "CCP": "âœ…" if s["level"] == "high" else "â€”",
        }
        # PDFì—ì„œ ê´€ë ¨ ë‚´ìš© ì°¾ê¸°
        if st.session_state.pdf_texts:
            mentions = 0
            for text in st.session_state.pdf_texts.values():
                if s["name"].replace("Â·", " ").split("Â·")[0] in text or s["name"].split("Â·")[-1] in text:
                    mentions += 1
            row["PDF ì–¸ê¸‰"] = f"ğŸ“„ {mentions}ê±´" if mentions > 0 else "â€”"
        else:
            row["PDF ì–¸ê¸‰"] = "â€”"
        compare_data.append(row)

    st.dataframe(pd.DataFrame(compare_data), use_container_width=True, hide_index=True)

    if st.session_state.pdf_texts:
        st.success(f"âœ… {len(st.session_state.pdf_texts)}ê°œ PDF ë¬¸ì„œ ì°¸ì¡° ì™„ë£Œ")
    else:
        st.info("PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¬¸ì„œ ë‚´ ê³µì • ê´€ë ¨ ë‚´ìš©ì´ ìë™ ë§¤ì¹­ë©ë‹ˆë‹¤")
